{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# GPT Training for Shakespeare data set"],"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"K-40g-z2fW9u"}},{"cell_type":"code","source":["!cd /kaggle/working"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:34:58.128829Z","iopub.execute_input":"2023-11-03T12:34:58.129070Z","iopub.status.idle":"2023-11-03T12:34:59.072862Z","shell.execute_reply.started":"2023-11-03T12:34:58.129048Z","shell.execute_reply":"2023-11-03T12:34:59.071408Z"},"trusted":true,"id":"H7z7SsNefW97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf S21\n","!git clone https://github.com/mHemaAP/S21.git"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:34:59.075399Z","iopub.execute_input":"2023-11-03T12:34:59.075809Z","iopub.status.idle":"2023-11-03T12:35:02.789083Z","shell.execute_reply.started":"2023-11-03T12:34:59.075771Z","shell.execute_reply":"2023-11-03T12:35:02.788013Z"},"trusted":true,"id":"EydSlMARfW-B","outputId":"e9c1eafc-ac8f-4b93-bee6-eff20ed0a7fc"},"execution_count":null,"outputs":[{"name":"stdout","text":"Cloning into 'S21'...\nremote: Enumerating objects: 9, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (9/9), 434.34 KiB | 5.50 MiB/s, done.\nResolving deltas: 100% (1/1), done.\n","output_type":"stream"}]},{"cell_type":"code","source":["cd S21"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:02.790380Z","iopub.execute_input":"2023-11-03T12:35:02.790647Z","iopub.status.idle":"2023-11-03T12:35:02.797359Z","shell.execute_reply.started":"2023-11-03T12:35:02.790622Z","shell.execute_reply":"2023-11-03T12:35:02.796065Z"},"trusted":true,"id":"Nm8lRLEXfW-G","outputId":"67e9b91b-64f1-42f1-fbf5-2982ebbf1314"},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working/S21\n","output_type":"stream"}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","import config as cfg"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:02.800298Z","iopub.execute_input":"2023-11-03T12:35:02.800998Z","iopub.status.idle":"2023-11-03T12:35:05.697824Z","shell.execute_reply.started":"2023-11-03T12:35:02.800972Z","shell.execute_reply":"2023-11-03T12:35:05.696854Z"},"trusted":true,"id":"4hYorUh4fW-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = cfg.device\n","block_size = cfg.block_size\n","batch_size = cfg.batch_size\n","eval_iters = cfg.eval_iters"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:05.699064Z","iopub.execute_input":"2023-11-03T12:35:05.699460Z","iopub.status.idle":"2023-11-03T12:35:05.703761Z","shell.execute_reply.started":"2023-11-03T12:35:05.699434Z","shell.execute_reply":"2023-11-03T12:35:05.702860Z"},"trusted":true,"id":"W95H9G9mfW-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","\n","# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","# here are all the unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","# create a mapping from characters to integers\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","# encoder: take a string, output a list of integers\n","encode = lambda s: [stoi[c] for c in s]\n","# decoder: take a list of integers, output a string\n","decode = lambda l: ''.join([itos[i] for i in l])"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:05.704782Z","iopub.execute_input":"2023-11-03T12:35:05.705040Z","iopub.status.idle":"2023-11-03T12:35:05.746807Z","shell.execute_reply.started":"2023-11-03T12:35:05.705018Z","shell.execute_reply":"2023-11-03T12:35:05.745961Z"},"trusted":true,"id":"KR8sh3U-fW-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train and test splits\n","data = torch.tensor(encode(text), dtype=torch.long)\n","# first 90% will be train, rest val\n","n = int(0.9*len(data))\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:05.747894Z","iopub.execute_input":"2023-11-03T12:35:05.748145Z","iopub.status.idle":"2023-11-03T12:35:06.021346Z","shell.execute_reply.started":"2023-11-03T12:35:05.748123Z","shell.execute_reply":"2023-11-03T12:35:06.020458Z"},"trusted":true,"id":"WwrNAD2jfW-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data loading\n","def get_batch(split):\n","    # generate a small batch of data of inputs x and targets y\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","\n","@torch.no_grad()\n","def estimate_loss(model):\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:06.022613Z","iopub.execute_input":"2023-11-03T12:35:06.023070Z","iopub.status.idle":"2023-11-03T12:35:06.031342Z","shell.execute_reply.started":"2023-11-03T12:35:06.023036Z","shell.execute_reply":"2023-11-03T12:35:06.030442Z"},"trusted":true,"id":"noXFF_9LfW-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt import GPTLanguageModel\n","\n","model = GPTLanguageModel(vocab_size)\n","m = model.to(device)\n","# print the number of parameters in the model\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate)\n","\n","for iter in range(cfg.max_iters):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % cfg.eval_interval == 0 or iter == cfg.max_iters - 1:\n","        losses = estimate_loss(model)\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","torch.save(model.state_dict(), 'gpt_model_saved.pth')\n"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T12:35:06.032469Z","iopub.execute_input":"2023-11-03T12:35:06.032750Z","iopub.status.idle":"2023-11-03T13:04:58.723377Z","shell.execute_reply.started":"2023-11-03T12:35:06.032711Z","shell.execute_reply":"2023-11-03T13:04:58.722463Z"},"trusted":true,"id":"6trBt4-NfW-T","outputId":"1464f227-5b1a-45d3-8f9f-d34c52b1d27a"},"execution_count":null,"outputs":[{"name":"stdout","text":"10.788929 M parameters\nstep 0: train loss 4.2221, val loss 4.2306\nstep 500: train loss 1.7587, val loss 1.9086\nstep 1000: train loss 1.3919, val loss 1.5998\nstep 1500: train loss 1.2673, val loss 1.5301\nstep 2000: train loss 1.1904, val loss 1.5142\nstep 2500: train loss 1.1194, val loss 1.5024\nstep 3000: train loss 1.0738, val loss 1.4949\nstep 3500: train loss 1.0213, val loss 1.5150\nstep 4000: train loss 0.9618, val loss 1.5183\nstep 4500: train loss 0.9087, val loss 1.5446\nstep 4999: train loss 0.8543, val loss 1.5633\n","output_type":"stream"}]},{"cell_type":"code","source":["# generate from the model\n","context = torch.zeros((1, 1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"],"metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:04:58.726623Z","iopub.execute_input":"2023-11-03T13:04:58.727021Z","iopub.status.idle":"2023-11-03T13:05:06.549005Z","shell.execute_reply.started":"2023-11-03T13:04:58.726984Z","shell.execute_reply":"2023-11-03T13:05:06.548018Z"},"trusted":true,"id":"Q-GiMXbOfW-X","outputId":"b917826b-deed-404d-bef1-ea022b3faae9"},"execution_count":null,"outputs":[{"name":"stdout","text":"\nWhich we thank they shall follow men;\nThat bear this news ere his tooth doth chase,\nMore than a doth to eunmoon on.\n\nCAMILLO:\nTell him,--\n\nFLORIZEL:\nWe then should not see your father vexations.\n\nCAMILLO:\nThe senators is, in some patient third--\n\nProvator:\nBid them well secohe st are then robes to Angelo?--\n\nMAMILLIA:\nBe never give better countend to live mock\nof your knees vent-on a young brother till\nyou shall be deted for my on yours.\n\nLEONTES:\n'For this same sighs of four; an yet, the throat\n","output_type":"stream"}]}]}